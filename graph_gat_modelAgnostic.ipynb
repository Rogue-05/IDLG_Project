{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjb7HH6ZVxE4",
        "outputId": "1db7ad33-89ba-44e2-faf0-12f1aa94991c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n"
      ],
      "metadata": {
        "id": "Hq_8eDSOUvGR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "_9_OnUHOUvyC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cora():\n",
        "    dataset = Planetoid(\n",
        "        root=\"./data\",\n",
        "        name=\"Cora\",\n",
        "        transform=NormalizeFeatures()\n",
        "    )\n",
        "    return dataset[0]\n"
      ],
      "metadata": {
        "id": "nGOY2rtkUxfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_label_splits(data, label_rate, seed):\n",
        "    set_seed(seed)\n",
        "\n",
        "    y = data.y.cpu().numpy()\n",
        "    num_nodes = data.num_nodes\n",
        "\n",
        "    idx = np.arange(num_nodes)\n",
        "\n",
        "    # First: fixed test set (20%)\n",
        "    sss1 = StratifiedShuffleSplit(\n",
        "        n_splits=1, test_size=0.2, random_state=seed\n",
        "    )\n",
        "    train_val_idx, test_idx = next(sss1.split(idx, y))\n",
        "\n",
        "    # Second: labeled subset from train+val\n",
        "    sss2 = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        train_size=label_rate,\n",
        "        random_state=seed\n",
        "    )\n",
        "    labeled_idx, _ = next(\n",
        "        sss2.split(train_val_idx, y[train_val_idx])\n",
        "    )\n",
        "    labeled_idx = train_val_idx[labeled_idx]\n",
        "\n",
        "    # Validation set = remaining train_val - labeled\n",
        "    val_idx = np.setdiff1d(train_val_idx, labeled_idx)\n",
        "\n",
        "    masks = {}\n",
        "    for name, indices in zip(\n",
        "        [\"train\", \"val\", \"test\"],\n",
        "        [labeled_idx, val_idx, test_idx]\n",
        "    ):\n",
        "        mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "        mask[indices] = True\n",
        "        masks[name] = mask\n",
        "\n",
        "    return masks\n"
      ],
      "metadata": {
        "id": "XmCr9-FhUzIp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_feature_ablation(x, ablation, seed, noise_level=None):\n",
        "    set_seed(seed)\n",
        "\n",
        "    if ablation == \"Vanilla\":\n",
        "        return x\n",
        "\n",
        "    if ablation == \"Identity\":\n",
        "        return torch.eye(x.size(0), device=x.device)\n",
        "\n",
        "    if ablation == \"Shuffled\":\n",
        "        perm = torch.randperm(x.size(0))\n",
        "        return x[perm]\n",
        "\n",
        "    if ablation == \"Gaussian\":\n",
        "        assert noise_level is not None\n",
        "        noise = torch.randn_like(x) * noise_level\n",
        "        return x + noise\n",
        "\n",
        "    raise ValueError(f\"Unknown feature ablation: {ablation}\")\n"
      ],
      "metadata": {
        "id": "91UZMtb6U0ov"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_structure_ablation(edge_index, ablation, seed):\n",
        "    set_seed(seed)\n",
        "\n",
        "    if ablation != \"EdgeDrop\":\n",
        "        return edge_index\n",
        "\n",
        "    num_edges = edge_index.size(1)\n",
        "    keep = int(0.8 * num_edges)\n",
        "    perm = torch.randperm(num_edges)[:keep]\n",
        "    return edge_index[:, perm]\n"
      ],
      "metadata": {
        "id": "L9UMzMMPU2i7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, out_dim, heads=8, dropout=0.6):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(\n",
        "            in_dim, hidden_dim, heads=heads, dropout=dropout\n",
        "        )\n",
        "        self.conv2 = GATConv(\n",
        "            hidden_dim * heads, out_dim, heads=1, dropout=dropout\n",
        "        )\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index, return_attn=False):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        if return_attn:\n",
        "            x, (edge_idx, attn1) = self.conv1(\n",
        "                x, edge_index, return_attention_weights=True\n",
        "            )\n",
        "        else:\n",
        "            x = self.conv1(x, edge_index)\n",
        "\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        if return_attn:\n",
        "            x, (_, attn2) = self.conv2(\n",
        "                x, edge_index, return_attention_weights=True\n",
        "            )\n",
        "            return x, [attn1, attn2]\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Nh4Wdy86U47S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def representation_variance(embeddings):\n",
        "    \"\"\"\n",
        "    embeddings: Tensor [num_nodes, dim]\n",
        "    Returns mean variance across dimensions.\n",
        "    \"\"\"\n",
        "    return embeddings.var(dim=0).mean().item()"
      ],
      "metadata": {
        "id": "sbFl3sUVjDN0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_entropy(attn_weights, eps=1e-9):\n",
        "    \"\"\"\n",
        "    attn_weights: Tensor of shape [num_edges, num_heads]\n",
        "    Returns mean entropy over edges.\n",
        "    \"\"\"\n",
        "    attn = attn_weights + eps\n",
        "    ent = -(attn * torch.log(attn)).sum(dim=1)\n",
        "    return ent.mean().item()\n",
        "\n",
        "\n",
        "def train_and_eval(\n",
        "    data,\n",
        "    masks,\n",
        "    feature_ablation,\n",
        "    structure_ablation,\n",
        "    noise_level,\n",
        "    seed,\n",
        "    device\n",
        "):\n",
        "    set_seed(seed)\n",
        "    data = data.to(device)\n",
        "\n",
        "    x = apply_feature_ablation(\n",
        "        data.x, feature_ablation, seed, noise_level\n",
        "    )\n",
        "    edge_index = apply_structure_ablation(\n",
        "        data.edge_index, structure_ablation, seed\n",
        "    )\n",
        "\n",
        "    model = GAT(\n",
        "        in_dim=x.size(1),\n",
        "        hidden_dim=8,\n",
        "        out_dim=int(data.y.max().item()) + 1\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=0.005,\n",
        "        weight_decay=5e-4\n",
        "    )\n",
        "\n",
        "    best_val = 0.0\n",
        "    best_epoch = 0\n",
        "    patience = 100\n",
        "    wait = 0\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # ---- training loop (unchanged) ----\n",
        "    for epoch in range(1, 1001):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(x, edge_index)\n",
        "        loss = F.cross_entropy(\n",
        "            out[masks[\"train\"]],\n",
        "            data.y[masks[\"train\"]]\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_pred = out[masks[\"val\"]].argmax(dim=1)\n",
        "            val_acc = (\n",
        "                val_pred == data.y[masks[\"val\"]]\n",
        "            ).float().mean().item()\n",
        "\n",
        "        if val_acc > best_val:\n",
        "            best_val = val_acc\n",
        "            best_epoch = epoch\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                break\n",
        "\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    # ---- final evaluation + attention diagnostics ----\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # forward with attention weights\n",
        "        out, attn = model(\n",
        "            x, edge_index, return_attn=True\n",
        "        )\n",
        "        rep_var = representation_variance(out)\n",
        "\n",
        "        test_pred = out[masks[\"test\"]].argmax(dim=1)\n",
        "        test_acc = (\n",
        "            test_pred == data.y[masks[\"test\"]]\n",
        "        ).float().mean().item()\n",
        "\n",
        "        # attention entropy per layer\n",
        "        attn_entropy_l1 = attention_entropy(attn[0])\n",
        "        attn_entropy_l2 = attention_entropy(attn[1])\n",
        "\n",
        "    return (\n",
        "        test_acc,\n",
        "        best_epoch,\n",
        "        train_time,\n",
        "        attn_entropy_l1,\n",
        "        attn_entropy_l2,\n",
        "        rep_var\n",
        "    )\n"
      ],
      "metadata": {
        "id": "pjZ8vAZDU6ia"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cora_gat_experiments(output_csv):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    data = load_cora()\n",
        "\n",
        "    label_rates = [0.01, 0.03, 0.05, 0.10]\n",
        "    seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "    ablations = [\n",
        "        (\"Vanilla\", None),\n",
        "        (\"Identity\", None),\n",
        "        (\"Shuffled\", None),\n",
        "        (\"Gaussian\", 0.1),\n",
        "        (\"Gaussian\", 0.3),\n",
        "        (\"Gaussian\", 0.5),\n",
        "        (\"EdgeDrop\", None)\n",
        "    ]\n",
        "\n",
        "    with open(output_csv, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "\n",
        "        # ---- updated CSV header ----\n",
        "        writer.writerow([\n",
        "            \"dataset\", \"model\", \"seed\", \"label_rate\", \"ablation\",\n",
        "            \"noise_level\", \"accuracy\", \"best_epoch\", \"train_time\",\n",
        "            \"attn_entropy_l1\", \"attn_entropy_l2\",\"rep_variance\"\n",
        "        ])\n",
        "\n",
        "        for seed in seeds:\n",
        "            for lr in label_rates:\n",
        "                masks = create_label_splits(data, lr, seed)\n",
        "\n",
        "                for ablation, noise in ablations:\n",
        "                    feat_ab = ablation if ablation != \"EdgeDrop\" else \"Vanilla\"\n",
        "                    struct_ab = ablation if ablation == \"EdgeDrop\" else None\n",
        "\n",
        "                    # ---- updated unpacking ----\n",
        "                    acc, epoch, t, ent1, ent2,rep_var = train_and_eval(\n",
        "                        data=data,\n",
        "                        masks=masks,\n",
        "                        feature_ablation=feat_ab,\n",
        "                        structure_ablation=struct_ab,\n",
        "                        noise_level=noise,\n",
        "                        seed=seed,\n",
        "                        device=device\n",
        "                    )\n",
        "\n",
        "                    writer.writerow([\n",
        "                        \"Cora\",\n",
        "                        \"GAT\",\n",
        "                        seed,\n",
        "                        lr,\n",
        "                        ablation,\n",
        "                        noise if noise is not None else \"NA\",\n",
        "                        acc,\n",
        "                        epoch,\n",
        "                        t,\n",
        "                        ent1,\n",
        "                        ent2,\n",
        "                        rep_var\n",
        "                    ])\n"
      ],
      "metadata": {
        "id": "j-Jxf2UsU9Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_cora_gat_experiments(\"gat_cora_results.csv\")\n"
      ],
      "metadata": {
        "id": "dMbT1YwbU_iO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_citeseer():\n",
        "    dataset = Planetoid(\n",
        "        root=\"./data\",\n",
        "        name=\"CiteSeer\",\n",
        "        transform=NormalizeFeatures()\n",
        "    )\n",
        "    return dataset[0]\n"
      ],
      "metadata": {
        "id": "8K8g0X84bnOl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_citeseer_gat_experiments(output_csv):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    data = load_citeseer()\n",
        "\n",
        "    label_rates = [0.01, 0.03, 0.05, 0.10]\n",
        "    seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "    ablations = [\n",
        "        (\"Vanilla\", None),\n",
        "        (\"Identity\", None),\n",
        "        (\"Shuffled\", None),\n",
        "        (\"Gaussian\", 0.1),\n",
        "        (\"Gaussian\", 0.3),\n",
        "        (\"Gaussian\", 0.5),\n",
        "        (\"EdgeDrop\", None)\n",
        "    ]\n",
        "\n",
        "    with open(output_csv, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "\n",
        "        # ---- updated CSV header ----\n",
        "        writer.writerow([\n",
        "            \"dataset\", \"model\", \"seed\", \"label_rate\", \"ablation\",\n",
        "            \"noise_level\", \"accuracy\", \"best_epoch\", \"train_time\",\n",
        "            \"attn_entropy_l1\", \"attn_entropy_l2\",\"rep_variance\"\n",
        "        ])\n",
        "\n",
        "        for seed in seeds:\n",
        "            for lr in label_rates:\n",
        "                masks = create_label_splits(data, lr, seed)\n",
        "\n",
        "                for ablation, noise in ablations:\n",
        "                    feat_ab = ablation if ablation != \"EdgeDrop\" else \"Vanilla\"\n",
        "                    struct_ab = ablation if ablation == \"EdgeDrop\" else None\n",
        "\n",
        "                    # ---- updated unpacking ----\n",
        "                    acc, epoch, t, ent1, ent2,rep_var = train_and_eval(\n",
        "                        data=data,\n",
        "                        masks=masks,\n",
        "                        feature_ablation=feat_ab,\n",
        "                        structure_ablation=struct_ab,\n",
        "                        noise_level=noise,\n",
        "                        seed=seed,\n",
        "                        device=device\n",
        "                    )\n",
        "\n",
        "                    writer.writerow([\n",
        "                        \"CiteSeer\",\n",
        "                        \"GAT\",\n",
        "                        seed,\n",
        "                        lr,\n",
        "                        ablation,\n",
        "                        noise if noise is not None else \"NA\",\n",
        "                        acc,\n",
        "                        epoch,\n",
        "                        t,\n",
        "                        ent1,\n",
        "                        ent2,\n",
        "                        rep_var\n",
        "                    ])"
      ],
      "metadata": {
        "id": "24kfozkibpkl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_citeseer_gat_experiments(\"gat_citeseer_model_agnostic.csv\")\n"
      ],
      "metadata": {
        "id": "q-k435rGbqFY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def generate_synthetic_heterophilous_graph(\n",
        "    num_nodes=2000,\n",
        "    num_classes=5,\n",
        "    feature_dim=128,\n",
        "    p_in=0.01,\n",
        "    p_out=0.05,\n",
        "    seed=0\n",
        "):\n",
        "    set_seed(seed)\n",
        "\n",
        "    # ---- labels ----\n",
        "    y = torch.randint(0, num_classes, (num_nodes,))\n",
        "\n",
        "    # ---- features (weakly correlated with labels) ----\n",
        "    class_means = torch.randn(num_classes, feature_dim)\n",
        "    x = torch.randn(num_nodes, feature_dim)\n",
        "    x[y == 0] += 0.2\n",
        "    x[y == 1] -= 0.2\n",
        "\n",
        "\n",
        "    # ---- edges (heterophily: more inter-class edges) ----\n",
        "    edge_list = []\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(i + 1, num_nodes):\n",
        "            if y[i] == y[j]:\n",
        "                if torch.rand(1).item() < p_in:\n",
        "                    edge_list.append([i, j])\n",
        "                    edge_list.append([j, i])\n",
        "            else:\n",
        "                if torch.rand(1).item() < p_out:\n",
        "                    edge_list.append([i, j])\n",
        "                    edge_list.append([j, i])\n",
        "\n",
        "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    data = Data(\n",
        "        x=x,\n",
        "        edge_index=edge_index,\n",
        "        y=y\n",
        "    )\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "lI1fm82Q7Xug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_synthetic(seed):\n",
        "    return generate_synthetic_heterophilous_graph(seed=seed)\n"
      ],
      "metadata": {
        "id": "_4tBmgwm7bC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_synthetic_gat_experiments(output_csv):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    label_rates = [0.01, 0.03, 0.05, 0.10]\n",
        "    seeds = [0, 1, 2, 3, 4]\n",
        "\n",
        "    ablations = [\n",
        "        (\"Vanilla\", None),\n",
        "        (\"Identity\", None),\n",
        "        (\"Shuffled\", None),\n",
        "        (\"Gaussian\", 0.1),\n",
        "        (\"Gaussian\", 0.3),\n",
        "        (\"Gaussian\", 0.5),\n",
        "        (\"EdgeDrop\", None)\n",
        "    ]\n",
        "\n",
        "    with open(output_csv, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\n",
        "            \"dataset\", \"model\", \"seed\", \"label_rate\", \"ablation\",\n",
        "            \"noise_level\", \"accuracy\", \"best_epoch\", \"train_time\"\n",
        "        ])\n",
        "\n",
        "        for seed in seeds:\n",
        "            data = load_synthetic(seed)\n",
        "\n",
        "            for lr in label_rates:\n",
        "                masks = create_label_splits(data, lr, seed)\n",
        "\n",
        "                for ablation, noise in ablations:\n",
        "                    feat_ab = ablation if ablation != \"EdgeDrop\" else \"Vanilla\"\n",
        "                    struct_ab = ablation if ablation == \"EdgeDrop\" else None\n",
        "\n",
        "                    acc, epoch, t = train_and_eval(\n",
        "                        data=data,\n",
        "                        masks=masks,\n",
        "                        feature_ablation=feat_ab,\n",
        "                        structure_ablation=struct_ab,\n",
        "                        noise_level=noise,\n",
        "                        seed=seed,\n",
        "                        device=device\n",
        "                    )\n",
        "\n",
        "                    writer.writerow([\n",
        "                        \"Synthetic-Heterophilous\",\n",
        "                        \"GAT\",\n",
        "                        seed,\n",
        "                        lr,\n",
        "                        ablation,\n",
        "                        noise if noise is not None else \"NA\",\n",
        "                        acc,\n",
        "                        epoch,\n",
        "                        t\n",
        "                    ])\n"
      ],
      "metadata": {
        "id": "-qLIY5ZX7qSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_synthetic_gat_experiments(\"gat_synthetic_results.csv\")\n"
      ],
      "metadata": {
        "id": "RcgsgV9j7sZq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}